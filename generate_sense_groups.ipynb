{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Sense Vectors to identify Word sense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Library Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import math\n",
    "from collections import defaultdict\n",
    "import ast\n",
    "from tqdm import tqdm\n",
    "\n",
    "from gensim.models import KeyedVectors\n",
    "import spacy\n",
    "import pandas as pd\n",
    "from spacy_wordnet.wordnet_annotator import WordnetAnnotator \n",
    "import plotly.graph_objects as go\n",
    "import igraph\n",
    "from igraph import Graph, EdgeSeq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Append the github repo to system path, and import modules from it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"sensegram_package/\")\n",
    "import sensegram\n",
    "from wsd import WSD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_vectors = False # Flag to decide to load sense and word vectors, to word with WSD module\n",
    "load_data = True # Flag to decide to load raw data\n",
    "generate_sense_embeddings = False # Flag to decide to use vectors to generate sense embeddings for each noun in corpus\n",
    "generate_hypernymy_flag = True # Flag to decide to use wordnet to generate hypernymy map for each noun in the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_directory = os.path.join(os.getcwd(), \"data\")\n",
    "corpus_fpath = os.path.join(data_directory, \"corpus.txt\")\n",
    "sense_vectors_fpath = os.path.join(data_directory, \"model\", \"wiki.txt.clusters.minsize5-1000-sum-score-20.sense_vectors\")\n",
    "word_vectors_fpath = os.path.join(data_directory, \"model\", \"wiki.txt.word_vectors\")\n",
    "corpus_data_sense_mappings_file = os.path.join(data_directory, \"corpus_sense_mapping.csv\")\n",
    "hhm_mappings_file = os.path.join(data_directory, \"hhm_mappings.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the sense and word vector files. This may take some time, owing to the large file size of the vector files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading the corpus now!\n"
     ]
    }
   ],
   "source": [
    "if load_vectors:\n",
    "    s = time.time()\n",
    "\n",
    "    if os.path.exists(sense_vectors_fpath) and os.path.exists(word_vectors_fpath):\n",
    "        sense_vectors = sensegram.SenseGram.load_word2vec_format(sense_vectors_fpath, binary=False)\n",
    "        word_vectors = KeyedVectors.load_word2vec_format(word_vectors_fpath, binary=False, unicode_errors=\"ignore\")\n",
    "        print(f\"Took {time.time()-s}seconds to load vector files\")\n",
    "    else:\n",
    "        print(\"Could not find vector files. Check file paths and ensure the right files exists\")\n",
    "    del s\n",
    "\n",
    "if load_data:\n",
    "    print(\"Reading the corpus now!\")\n",
    "    with open(corpus_fpath, \"r\") as f:\n",
    "        corpus_data = f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get all senses of a word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the sense vectors, load all possible senses for the given word.  \n",
    "The output prints the sense *Word#&lt;sense-number&gt;* followed by the probabilities of that word matching other words with similar sense. This table can help us provide logical names of different sense groups. For example, running the code for the word \"**table**\" gives the following output -  \n",
    "```\n",
    "Probabilities of the senses:\n",
    "[('Table#1', 1.0), ('Table#2', 1.0), ('Table#3', 1.0), ('Table#4', 1.0), ('table#1', 1.0), ('table#2', 1.0), ('table#3', 1.0), ('table#4', 1.0)]\n",
    "\n",
    "\n",
    "Table#1\n",
    "====================\n",
    "table#1 0.996316\n",
    "TABLE#1 0.993647\n",
    "PAGE#2 0.989991\n",
    "page#2 0.989991\n",
    "WINDOW#2 0.989900\n",
    "Window#3 0.989900\n",
    "window#2 0.989900\n",
    "Scale#2 0.989745\n",
    "scale#2 0.989745\n",
    "SCALE#2 0.989745\n",
    "\n",
    "\n",
    "Table#2\n",
    "====================\n",
    "TABLE#2 1.000000\n",
    "Row#3 0.869726\n",
    "row#3 0.869726\n",
    "ROW#3 0.856643\n",
    "Stack#3 0.829349\n",
    "Box#3 0.826571\n",
    "BOX#2 0.826571\n",
    "stack#3 0.825068\n",
    "STACK#3 0.824239\n",
    "BOWL#3 0.813412\n",
    "\n",
    "\n",
    "Table#3\n",
    "====================\n",
    "TABLE#3 0.939938\n",
    "table#3 0.934190\n",
    "Boundary_Markers#5 0.845184\n",
    "Catchment_Basins#2 0.826906\n",
    "contents#2 0.825448\n",
    "CONTENTS#2 0.825448\n",
    "Contents#2 0.824324\n",
    "tables#1 0.806271\n",
    "NUMBERS#3 0.804637\n",
    "Tables#1 0.796628\n",
    "....\n",
    "\n",
    "```\n",
    "Few things we can see from the output - \n",
    "* Since we have set *ignore_case=True*, the output shows 4 senses for *Table*, and 4 for *table*.\n",
    "* Looking at the related words for each sense, we can attribute the following logical groups to few of the senses - \n",
    "    - Table#2 - Data table.  \n",
    "    - Table#3 - Table of contents.\n",
    "    - table#4 - Hotel/Furniture.\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities of the senses:\n",
      "[('disk#1', 1.0), ('disk#2', 1.0), ('disk#3', 1.0), ('disk#4', 1.0), ('disk#5', 1.0)]\n",
      "\n",
      "\n",
      "Disk#1\n",
      "====================\n",
      "Flexible_Disk#2 0.924806\n",
      "Rigid_Disk#2 0.916348\n",
      "Basic_Input#1 0.899887\n",
      "RDOS#1 0.893633\n",
      "SASI#1 0.891424\n",
      "Sasi#1 0.891424\n",
      "corrector#4 0.889009\n",
      "customizer#2 0.888149\n",
      "Fargo#3 0.886290\n",
      "fargo#2 0.886290\n",
      "\n",
      "\n",
      "Disk#2\n",
      "====================\n",
      "DISK#2 0.991812\n",
      "BOOT#4 0.958993\n",
      "Bit#4 0.934779\n",
      "disk#2 0.931051\n",
      "module#3 0.923883\n",
      "Module#3 0.921607\n",
      "MODULE#3 0.916528\n",
      "Disks#3 0.909954\n",
      "rom#1 0.903984\n",
      "hard_disk#1 0.903680\n",
      "\n",
      "\n",
      "Disk#3\n",
      "====================\n",
      "disk#3 1.000000\n",
      "DISK#3 1.000000\n",
      "urn#4 0.960472\n",
      "URN#4 0.960472\n",
      "Urn#4 0.960472\n",
      "EXEC#4 0.958112\n",
      "Coco#4 0.957627\n",
      "CoCo#2 0.957627\n",
      "coco#3 0.957627\n",
      "COCO#2 0.957627\n",
      "\n",
      "\n",
      "Disk#4\n",
      "====================\n",
      "DISK#4 1.000000\n",
      "disk#4 0.991975\n",
      "Envelope#1 0.931414\n",
      "Plate#1 0.922727\n",
      "Stack#3 0.906151\n",
      "STACK#3 0.904850\n",
      "Shelf#4 0.900630\n",
      "stack#3 0.897358\n",
      "Bubble#4 0.896194\n",
      "CHAIN#4 0.895439\n",
      "\n",
      "\n",
      "disk#1\n",
      "====================\n",
      "DISK#1 0.995354\n",
      "Modem#2 0.961432\n",
      "install#3 0.960586\n",
      "SYNC#1 0.960527\n",
      "sync#1 0.960527\n",
      "Install#1 0.959036\n",
      "Handheld#2 0.958145\n",
      "laptop#1 0.956479\n",
      "Laptop#1 0.956479\n",
      "adapter#3 0.955576\n",
      "\n",
      "\n",
      "disk#2\n",
      "====================\n",
      "Hard_Disk#1 0.951037\n",
      "hard_disk#1 0.951037\n",
      "Disk_Drive#1 0.949592\n",
      "disk_drive#1 0.949592\n",
      "Disks#3 0.948765\n",
      "USB_flash#1 0.947548\n",
      "RAM_disk#2 0.947467\n",
      "Floppy#1 0.946784\n",
      "RAID_array#1 0.946609\n",
      "Floppy_disk#1 0.943072\n",
      "\n",
      "\n",
      "disk#3\n",
      "====================\n",
      "Disk#3 1.000000\n",
      "DISK#3 1.000000\n",
      "urn#4 0.960472\n",
      "URN#4 0.960472\n",
      "Urn#4 0.960472\n",
      "EXEC#4 0.958112\n",
      "Coco#4 0.957627\n",
      "CoCo#2 0.957627\n",
      "coco#3 0.957627\n",
      "COCO#2 0.957627\n",
      "\n",
      "\n",
      "disk#4\n",
      "====================\n",
      "Disk#4 0.991975\n",
      "DISK#4 0.991975\n",
      "Envelope#1 0.919594\n",
      "Plate#1 0.909810\n",
      "Diaphragm#1 0.896887\n",
      "diaphragm#1 0.892381\n",
      "Bulb#3 0.891742\n",
      "CHAIN#4 0.890951\n",
      "Stack#3 0.890267\n",
      "STACK#3 0.889386\n",
      "\n",
      "\n",
      "disk#5\n",
      "====================\n",
      "gaseous_envelope#1 0.940637\n",
      "Protostar#2 0.939690\n",
      "protostar#2 0.939690\n",
      "circumstellar_disk#1 0.933108\n",
      "accretion_disk#1 0.931165\n",
      "ergosphere#2 0.930390\n",
      "protoplanetary_disc#1 0.930362\n",
      "accretion_disc#2 0.929459\n",
      "protoplanetary_disk#1 0.928282\n",
      "spheroid#4 0.926040\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if load_vectors:\n",
    "    test_word = \"disk\"\n",
    "\n",
    "    print(\"Probabilities of the senses:\\n{}\\n\\n\".format(sense_vectors.get_senses(test_word, ignore_case=False)))\n",
    "\n",
    "    for sense_id, prob in sense_vectors.get_senses(test_word, ignore_case=True):\n",
    "        print(sense_id)\n",
    "        print(\"=\"*20)\n",
    "        for rsense_id, sim in sense_vectors.wv.most_similar(sense_id):\n",
    "            print(\"{} {:f}\".format(rsense_id, sim))\n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get disambiguated sense of the word, using corpus as context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Input\n",
    "To understand the word's sense in a given context, we use the *WSD* class from the sensegram library.  \n",
    "The WSD model takes the following key parameters to decide word sense based on corpus context - \n",
    "* vectors - Both sense and word vector models loaded earlier.  \n",
    "  \n",
    "  \n",
    "* method - To calculate the sense of the word, the library averages the sense scores of all the surrounding context words and compares it with different senses of the target word. For this comparison, there are two available metrics - \n",
    " - sim: Uses cosine distance\n",
    " - prob: Use log probability score  \n",
    "  \n",
    "  \n",
    "* window - This is the window(±) that the model looks into, to decide the word context.   \n",
    "For example, if our target word is *table*,   \n",
    "with the context of *\"we load the our data into a data-frame table object and count the number of rows/columns using the .shape method\"*  \n",
    " 1. a window of 3 would consider the following 6(3 on the left, and 3 on the right) words around our context word to find the sense of the word - *into, a, data-frame, object, and, count*  \n",
    " 2. a window of 5 would use the following context - *our, data, into, a, data-frame, table, object, and, count, the, number*  \n",
    "  \n",
    "  \n",
    "* verbose - Allows to print intermediate outputs while running the disambiguation code\n",
    "\n",
    "<hr>  \n",
    "     \n",
    "Some food-for-thought regarding the usage of WSD module - \n",
    " - Do note that while stopwords like *and* and *the* are considered in the context of the the target word, they are dropped while disambiguating the sense of our target.\n",
    " - While it may seem ideal to choose a high value of window for getting the sense of the target word, it may happen that the wider window results in an less accurate output, as it averages across all possible senses.\n",
    " - The library considers, and disambiguates, only the first occurance of the target word in the context. For a large corpus, it would be ideal to first split the corpus and generate contexts using an external helper function, and then iteratively get the sense for the target word across all occurances in the corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if load_vectors:\n",
    "    wsd_model = WSD(sense_vectors, word_vectors, window=15, method='prob', verbose=True)\n",
    "else:\n",
    "    print(\"Load vectors to initialize and work with WSD model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted context words:\n",
      "['know', 'hare', 'street', 'hope', 'overexcited', 'dont', 'er', 'richard', 'still', 'aaw', 'say', 'welcome', 'open', 'poppet', 'closed', 'gif', 'tortoise', 'youre', 'got']\n",
      "Senses of a target word:\n",
      "[('pizza#1', 1.0), ('pizza#2', 1.0)]\n",
      "Significance scores of context words:\n",
      "[0.29148820525520214, 0.12975690243744742, 0.02722264833952448, 0.11942657176932528, 0.009472310267542472, 0.16188559353799392, 0.1438541919856201, 0.13226385889523357, 0.33827481693934414, 0.01728681152264855, 0.3557976824709924, 0.06579240374490092, 0.11683631808681638, 0.07629630608727012, 0.4041725965133941, 0.025504092740760764, 0.16010984464621203, 0.04979557551486591, 0.34149093466603153]\n",
      "Context words:\n",
      "closed\t0.404\n",
      "say\t0.356\n",
      "got\t0.341\n",
      "('pizza#2', [0.7334760438909177, 0.7729272994918818])\n"
     ]
    }
   ],
   "source": [
    "if load_vectors:\n",
    "    print(wsd_model.disambiguate(corpus_data, \"pizza\"))\n",
    "else:\n",
    "    print(\"Load vectors to initialize and work with WSD model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5> Output </h5>  \n",
    "\n",
    "Running the Sense disambiguation code generates following lines of output -  \n",
    "1. Prints the context words extracted from the corpus.\n",
    "- Prints possible senses of the word, with their respective probabilities(without considering the context)\n",
    "- Prints the significance score of each context word.\n",
    "- Prints the most significant context words.\n",
    "- **Returns** a tuple of the sense of the word as derived from the context, and match scores(log-probability or cosine-similarity depending on the *method* chosen) of various senses of the target word.  \n",
    "For instance, the output *('table#2', [0.2706353009709064, 0.9591583572384959, 0.40617065436041355, 0.6940131864117054])* indicates the following things regarding our target word -  \n",
    "    - The closest sense of our target word is with *table#2*, with a match score of 0.959(second in the list)\n",
    "    - For the other senses, the match score can be read as follows - \n",
    "    - table#1 - 0.2706\n",
    "    - table#2 - 0.959\n",
    "    - table#3 - 0.406\n",
    "    - table#4 - 0.694\n",
    "\n",
    "Since we had not defined the *ignore_case* argument while initializing the WSD model, it resorts to the default of True, and the output return scores for the 4 senses of the word *table*.  \n",
    "If we chose to ignore case, the output would have match for 8 senses(4-Table; 4-table)\n",
    "<hr> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24929"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_data.find(\"pizza\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate sense embeddings from corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_corpus_data_with_context(corpus_filepath, window=5, force_update=False):\n",
    "    nlp = spacy.load('en')\n",
    "    with open(corpus_fpath, \"r\") as f:\n",
    "        corpus_data = f.readlines()\n",
    "    out_file = os.path.join(os.path.dirname(corpus_fpath), f\"window_{window}_context_corpus.txt\")\n",
    "    contextual_data = []\n",
    "    if os.path.exists(out_file) and (not force_update):\n",
    "        print(\"Found preexisting file. Loading context data from file\")\n",
    "        with open(out_file, \"r\") as f:\n",
    "            contextual_data = f.readlines()\n",
    "    else:\n",
    "        print(\"No pre created corpus found, or force update flag is true. Generating contextual data from corpus\")\n",
    "        with open(out_file, \"w\") as f:\n",
    "            for txt_line in corpus_data:\n",
    "                nlp_data = nlp(txt_line.replace(\"\\n\", \"\"))\n",
    "                max_tokens = len(nlp_data)\n",
    "                for i, tok in enumerate(nlp_data):\n",
    "                    if \"NN\" in tok.tag_:\n",
    "                        start = max(0, i-window)\n",
    "                        end = min(i+window, max_tokens)\n",
    "                        left_context = [t.text for t in nlp_data[start:i]] + [f\"<{tok.text}>\"]\n",
    "                        right_context = [t.text for t in nlp_data[i+1:end]]\n",
    "                        noun_in_context = f\"<{tok.text}> - {' '.join(left_context + right_context)}\"\n",
    "                        contextual_data.append(noun_in_context)\n",
    "                        f.write(noun_in_context + \"\\n\")\n",
    "    return contextual_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sense_group_from_corpus(context_data, wsd_model, sense_vectors, output_file):\n",
    "    output = {\n",
    "        \"word\": [],\n",
    "        \"context\": [],\n",
    "        \"sense_id\": [],\n",
    "        \"sense_group_name\": [],\n",
    "        \"sense_group_num\": [],\n",
    "        \"sense_probability\": [],\n",
    "        \"related_senses\": []\n",
    "    }\n",
    "    \n",
    "    for row in tqdm(context_data, total=len(context_data)):\n",
    "        word, ctx = row.split(' - ')\n",
    "        sense_id, sense_probs = wsd_model.disambiguate(ctx, word)\n",
    "        sense_probability = max(sense_probs)\n",
    "        sense_group_name, sense_group_num = sense_id.split(\"#\")\n",
    "        try:\n",
    "            related_senses = [r_senseid for r_senseid,_ in sense_vectors.wv.most_similar(sense_id)]\n",
    "            related_senses_l2 = [r_senseid for related_sense in related_senses for r_senseid,_ in sense_vectors.wv.most_similar(related_sense)]\n",
    "        except KeyError as e:\n",
    "            print(f\"Could not get related senses for {sense_id}\")\n",
    "            related_senses = []\n",
    "            related_senses_l2 = []\n",
    "        output[\"word\"].append(word)\n",
    "        output[\"context\"].append(ctx)\n",
    "        output[\"sense_id\"].append(sense_id)\n",
    "        output[\"sense_group_name\"].append(sense_group_name)\n",
    "        output[\"sense_group_num\"].append(sense_group_num)\n",
    "        output[\"sense_probability\"].append(sense_probability)\n",
    "        output[\"related_senses\"].append(related_senses+related_senses_l2)\n",
    "    \n",
    "    output_df = pd.DataFrame(output)\n",
    "    output_df.to_csv(output_file, index=False)\n",
    "    \n",
    "    return output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "window = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(corpus_data_sense_mappings_file) or generate_sense_embeddings:\n",
    "    wsd_model2 = WSD(sense_vectors, word_vectors, window=window, method='prob', verbose=False)\n",
    "    contextual_data = prepare_corpus_data_with_context(corpus_fpath, window=window, force_update=False)\n",
    "    sense_group_dataframe = get_sense_group_from_corpus(contextual_data, wsd_model2, sense_vectors, corpus_data_sense_mappings_file)\n",
    "else:\n",
    "    sense_group_dataframe = pd.read_csv(corpus_data_sense_mappings_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>context</th>\n",
       "      <th>sense_id</th>\n",
       "      <th>sense_group_name</th>\n",
       "      <th>sense_group_num</th>\n",
       "      <th>sense_probability</th>\n",
       "      <th>related_senses</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;english&gt;</td>\n",
       "      <td>can not stop listening to what have the &lt;engli...</td>\n",
       "      <td>english#6</td>\n",
       "      <td>english</td>\n",
       "      <td>6</td>\n",
       "      <td>0.962645</td>\n",
       "      <td>['English#6', 'ENGLISH#6', 'bengali#1', 'Sinha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;saturday&gt;</td>\n",
       "      <td>can not stop listening to what have the englis...</td>\n",
       "      <td>saturday#1</td>\n",
       "      <td>saturday</td>\n",
       "      <td>1</td>\n",
       "      <td>0.985751</td>\n",
       "      <td>['Saturday#2', 'SATURDAY#2', 'SUNDAY#3', 'sund...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;bit&gt;</td>\n",
       "      <td>not stop listening to what have the english by...</td>\n",
       "      <td>bit#6</td>\n",
       "      <td>bit</td>\n",
       "      <td>6</td>\n",
       "      <td>0.987740</td>\n",
       "      <td>['Bit#5', 'BIT#5', 'stuff#3', 'Stuff#2', 'Real...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;one&gt;</td>\n",
       "      <td>the &lt;one&gt; there is amazing had such a laugh wh...</td>\n",
       "      <td>one#3</td>\n",
       "      <td>one</td>\n",
       "      <td>3</td>\n",
       "      <td>0.969355</td>\n",
       "      <td>['One#3', 'ONE#3', 'List#10', 'Top#8', 'TOP#9'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;laugh&gt;</td>\n",
       "      <td>the one there is amazing had such a &lt;laugh&gt; wh...</td>\n",
       "      <td>laugh#1</td>\n",
       "      <td>laugh</td>\n",
       "      <td>1</td>\n",
       "      <td>0.914474</td>\n",
       "      <td>['LAUGH#1', 'Laugh#2', 'giggle#1', 'Giggle#1',...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         word                                            context    sense_id  \\\n",
       "0   <english>  can not stop listening to what have the <engli...   english#6   \n",
       "1  <saturday>  can not stop listening to what have the englis...  saturday#1   \n",
       "2       <bit>  not stop listening to what have the english by...       bit#6   \n",
       "3       <one>  the <one> there is amazing had such a laugh wh...       one#3   \n",
       "4     <laugh>  the one there is amazing had such a <laugh> wh...     laugh#1   \n",
       "\n",
       "  sense_group_name  sense_group_num  sense_probability  \\\n",
       "0          english                6           0.962645   \n",
       "1         saturday                1           0.985751   \n",
       "2              bit                6           0.987740   \n",
       "3              one                3           0.969355   \n",
       "4            laugh                1           0.914474   \n",
       "\n",
       "                                      related_senses  \n",
       "0  ['English#6', 'ENGLISH#6', 'bengali#1', 'Sinha...  \n",
       "1  ['Saturday#2', 'SATURDAY#2', 'SUNDAY#3', 'sund...  \n",
       "2  ['Bit#5', 'BIT#5', 'stuff#3', 'Stuff#2', 'Real...  \n",
       "3  ['One#3', 'ONE#3', 'List#10', 'Top#8', 'TOP#9'...  \n",
       "4  ['LAUGH#1', 'Laugh#2', 'giggle#1', 'Giggle#1',...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sense_group_dataframe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hypernymy extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = {\n",
    "    \"direct_match\": 8,\n",
    "    \"direct_nomatch\": 5,\n",
    "    \"l1_match\": 3,\n",
    "    \"l1_nomatch\": 2,\n",
    "    \"l2_match\": 1,\n",
    "    \"l2_nomatch\": 0.5,\n",
    "}\n",
    "\n",
    "nlp = spacy.load(\"en\")\n",
    "nlp.add_pipe(WordnetAnnotator(nlp.lang), after='tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_hypernymy(word, idx, hypernymy_dict, level=\"l1\"):\n",
    "    token = nlp(str(word))[0]\n",
    "    synsets = token._.wordnet.synsets()\n",
    "    for syn in synsets:\n",
    "        if syn.name().split(\".n.\")[0] == word and int(syn.name().split(\".n.\")[1]) == idx:\n",
    "            match_str = \"match\"\n",
    "        else:\n",
    "            match_str = \"nomatch\"\n",
    "\n",
    "        hypernym_syn = syn.hypernyms()\n",
    "        hyponym_syn = syn.hyponyms()\n",
    "        meronym_syn = syn.part_meronyms()\n",
    "        if len(hypernym_syn) >0:\n",
    "            hypernym = hypernym_syn[0].name().split('.')[0]\n",
    "            rev_map = {\n",
    "#                 f\"{word}#{idx}\":syn,\n",
    "                \"hyponyms\": [hyp.name().split(\".\")[0] for hyp in hyponym_syn],\n",
    "                \"meronyms\": [mero.name().split(\".\")[0] for mero in meronym_syn]\n",
    "            }\n",
    "            \n",
    "            if level in hypernymy_dict[hypernym][\"rev_map\"]:\n",
    "                hypernymy_dict[hypernym][\"rev_map\"][level].append(rev_map) \n",
    "            else:\n",
    "                hypernymy_dict[hypernym][\"rev_map\"][level] = [rev_map]\n",
    "\n",
    "            if \"sum_weight\" in hypernymy_dict[hypernym]:\n",
    "                hypernymy_dict[hypernym][\"sum_weight\"] += weights[f\"{level}_{match_str}\"]\n",
    "            else:\n",
    "                hypernymy_dict[hypernym][\"sum_weight\"] = weights[f\"{level}_{match_str}\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_hyponyms_meronym(hypernymy_dict, hypernym, kind=\"hyponyms\"):\n",
    "    nym = []\n",
    "    reverse_map = hypernymy_dict[hypernym]['rev_map']\n",
    "    extract_from = []\n",
    "    if \"direct\" in reverse_map:\n",
    "        extract_from.append(\"direct\")\n",
    "    if \"l1\" in reverse_map:\n",
    "        extract_from.append(\"l1\")\n",
    "    \n",
    "    for relation in extract_from:\n",
    "        num_relations = len(reverse_map[relation])\n",
    "        for i in range(num_relations):\n",
    "            nym += reverse_map[relation][i][kind]\n",
    "            \n",
    "    return list(set(nym))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1351/1351 [01:18<00:00, 17.32it/s]\n"
     ]
    }
   ],
   "source": [
    "if generate_hypernymy_flag:\n",
    "    all_hypernyms = []\n",
    "    all_hhm_map = []\n",
    "    all_hyponyms = []\n",
    "    all_meronyms = []\n",
    "\n",
    "    all_hypernyms_from_corpus = []\n",
    "    all_hyponyms_from_corpus = []\n",
    "    all_meronyms_from_corpus = []\n",
    "    num_words = len(sense_group_dataframe)\n",
    "    for _, row in tqdm(sense_group_dataframe[[\"sense_group_name\", \"sense_group_num\", \"related_senses\"]].iterrows(), total=num_words):\n",
    "        word, idx, r_senses = row\n",
    "\n",
    "        hypernymy_dict = defaultdict(lambda: defaultdict(dict))\n",
    "        generate_hypernymy(word, idx, hypernymy_dict, level=\"direct\")\n",
    "        r_senses_list = ast.literal_eval(r_senses)\n",
    "        for w in r_senses_list:\n",
    "            related_word, related_idx = str(w).split(\"#\")\n",
    "            if related_word in corpus_data:\n",
    "                generate_hypernymy(related_word, related_idx, hypernymy_dict)\n",
    "        hypernyms = []\n",
    "        hyponyms = []\n",
    "        meronyms = []   \n",
    "        hypernyms_from_corpus = []\n",
    "        hyponyms_from_corpus = []\n",
    "        meronyms_from_corpus = []\n",
    "        if len(hypernymy_dict)>0:\n",
    "            hypernymy_dict_sorted = {k: dict(v) for k, v in sorted(hypernymy_dict.items(), key=lambda item: item[1]['sum_weight'], reverse=True)}\n",
    "\n",
    "            hypernyms = list(hypernymy_dict_sorted.keys())\n",
    "            for hypernym in hypernyms:\n",
    "                extracted_hyponyms = extract_hyponyms_meronym(hypernymy_dict_sorted, hypernym, kind=\"hyponyms\")\n",
    "                extracted_meronyms = extract_hyponyms_meronym(hypernymy_dict_sorted, hypernym, kind=\"meronyms\")\n",
    "                hyponyms.append(extracted_hyponyms)\n",
    "                meronyms.append(extracted_meronyms)\n",
    "                \n",
    "                if hypernym.replace(\"_\", \" \") in corpus_data:\n",
    "                    hypernyms_from_corpus.append(hypernym)\n",
    "                    extracted_hyponyms_from_corpus = [hypo for hypo in extracted_hyponyms if hypo.replace(\"_\", \" \") in corpus_data]\n",
    "                    extracted_meronyms_from_corpus = [mero for mero in extracted_meronyms if mero.replace(\"_\", \" \") in corpus_data]\n",
    "                    hyponyms_from_corpus.append(extracted_hyponyms)\n",
    "                    meronyms_from_corpus.append(extracted_meronyms)\n",
    "\n",
    "        all_hypernyms.append(hypernyms)\n",
    "        all_hyponyms.append(hyponyms)\n",
    "        all_meronyms.append(meronyms)\n",
    "        all_hypernyms_from_corpus.append(hypernyms_from_corpus)\n",
    "        all_hyponyms_from_corpus.append(hyponyms_from_corpus)\n",
    "        all_meronyms_from_corpus.append(meronyms_from_corpus)\n",
    "        all_hhm_map.append(hypernymy_dict_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "if generate_hypernymy_flag:\n",
    "    sense_group_dataframe[\"hhm_map\"] = all_hhm_map\n",
    "    sense_group_dataframe[\"hypernym\"] = all_hypernyms\n",
    "    sense_group_dataframe[\"hyponym\"] = all_hyponyms\n",
    "    sense_group_dataframe[\"meronym\"] = all_meronyms\n",
    "    sense_group_dataframe[\"hypernym_from_corpus\"] = all_hypernyms_from_corpus\n",
    "    sense_group_dataframe[\"hyponym_from_corpus\"] = all_hyponyms_from_corpus\n",
    "    sense_group_dataframe[\"meronym_from_corpus\"] = all_meronyms_from_corpus\n",
    "    sense_group_dataframe.to_csv(hhm_mappings_file, index=False)\n",
    "else:\n",
    "    print(\"Neither generate hypernymy flag, nor hhm mappings file is present. Set the appropriate flags to proceed further\")\n",
    "    \n",
    "hhm_mappings_df = pd.read_csv(hhm_mappings_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hhm_mappings_file = os.path.join(\"hhm_mappings.csv\")\n",
    "# sense_group_dataframe = pd.read_csv(hhm_mappings_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "hhm_mappings_df = pd.read_csv(hhm_mappings_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>context</th>\n",
       "      <th>sense_id</th>\n",
       "      <th>sense_group_name</th>\n",
       "      <th>sense_group_num</th>\n",
       "      <th>sense_probability</th>\n",
       "      <th>related_senses</th>\n",
       "      <th>hhm_map</th>\n",
       "      <th>hypernym</th>\n",
       "      <th>hyponym</th>\n",
       "      <th>meronym</th>\n",
       "      <th>hypernym_from_corpus</th>\n",
       "      <th>hyponym_from_corpus</th>\n",
       "      <th>meronym_from_corpus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;english&gt;</td>\n",
       "      <td>can not stop listening to what have the &lt;engli...</td>\n",
       "      <td>english#6</td>\n",
       "      <td>english</td>\n",
       "      <td>6</td>\n",
       "      <td>0.962645</td>\n",
       "      <td>['English#6', 'ENGLISH#6', 'bengali#1', 'Sinha...</td>\n",
       "      <td>{'west_germanic': {'rev_map': {'direct': [{'hy...</td>\n",
       "      <td>['west_germanic', 'nation', 'humanistic_discip...</td>\n",
       "      <td>[['middle_english', 'received_pronunciation', ...</td>\n",
       "      <td>[[], [], [], []]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;saturday&gt;</td>\n",
       "      <td>can not stop listening to what have the englis...</td>\n",
       "      <td>saturday#1</td>\n",
       "      <td>saturday</td>\n",
       "      <td>1</td>\n",
       "      <td>0.985751</td>\n",
       "      <td>['Saturday#2', 'SATURDAY#2', 'SUNDAY#3', 'sund...</td>\n",
       "      <td>{'weekday': {'rev_map': {'direct': [{'hyponyms...</td>\n",
       "      <td>['weekday', 'rest_day']</td>\n",
       "      <td>[['whitmonday', 'whit-tuesday'], []]</td>\n",
       "      <td>[[], []]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;bit&gt;</td>\n",
       "      <td>not stop listening to what have the english by...</td>\n",
       "      <td>bit#6</td>\n",
       "      <td>bit</td>\n",
       "      <td>6</td>\n",
       "      <td>0.987740</td>\n",
       "      <td>['Bit#5', 'BIT#5', 'stuff#3', 'Stuff#2', 'Real...</td>\n",
       "      <td>{'be': {'rev_map': {'l1': [{'hyponyms': ['feel...</td>\n",
       "      <td>['be', 'fragment', 'look', 'touch', 'unit_of_m...</td>\n",
       "      <td>[['glitter', 'cut', 'sound', 'make', 'pass_off...</td>\n",
       "      <td>[[], [], [], [], [], [], [], [], [], [], [], [...</td>\n",
       "      <td>['be', 'look', 'time', 'performance', 'part', ...</td>\n",
       "      <td>[['glitter', 'cut', 'sound', 'make', 'pass_off...</td>\n",
       "      <td>[[], [], [], [], [], [], [], [], [], [], [], [...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;one&gt;</td>\n",
       "      <td>the &lt;one&gt; there is amazing had such a laugh wh...</td>\n",
       "      <td>one#3</td>\n",
       "      <td>one</td>\n",
       "      <td>3</td>\n",
       "      <td>0.969355</td>\n",
       "      <td>['One#3', 'ONE#3', 'List#10', 'Top#8', 'TOP#9'...</td>\n",
       "      <td>{'digit': {'rev_map': {'direct': [{'hyponyms':...</td>\n",
       "      <td>['digit', 'unit', 'travel', 'line', 'dispute',...</td>\n",
       "      <td>[['monad', 'singleton'], [], ['stalk', 'tailga...</td>\n",
       "      <td>[[], [], [], [], [], [], [], [], [], ['feather...</td>\n",
       "      <td>['digit', 'line', 'sport', 'result', 'be', 'ch...</td>\n",
       "      <td>[['monad', 'singleton'], ['terrace', 'serratio...</td>\n",
       "      <td>[[], [], ['feather'], [], [], [], [], [], [], ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;laugh&gt;</td>\n",
       "      <td>the one there is amazing had such a &lt;laugh&gt; wh...</td>\n",
       "      <td>laugh#1</td>\n",
       "      <td>laugh</td>\n",
       "      <td>1</td>\n",
       "      <td>0.914474</td>\n",
       "      <td>['LAUGH#1', 'Laugh#2', 'giggle#1', 'Giggle#1',...</td>\n",
       "      <td>{'laugh': {'rev_map': {'l1': [{'hyponyms': [],...</td>\n",
       "      <td>['laugh', 'express_emotion', 'complain', 'utte...</td>\n",
       "      <td>[[], ['cachinnate', 'bellylaugh', 'cackle', 'g...</td>\n",
       "      <td>[[], [], [], [], [], [], [], []]</td>\n",
       "      <td>['laugh', 'utter', 'sound', 'moment']</td>\n",
       "      <td>[[], [], [], []]</td>\n",
       "      <td>[[], [], [], []]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         word                                            context    sense_id  \\\n",
       "0   <english>  can not stop listening to what have the <engli...   english#6   \n",
       "1  <saturday>  can not stop listening to what have the englis...  saturday#1   \n",
       "2       <bit>  not stop listening to what have the english by...       bit#6   \n",
       "3       <one>  the <one> there is amazing had such a laugh wh...       one#3   \n",
       "4     <laugh>  the one there is amazing had such a <laugh> wh...     laugh#1   \n",
       "\n",
       "  sense_group_name  sense_group_num  sense_probability  \\\n",
       "0          english                6           0.962645   \n",
       "1         saturday                1           0.985751   \n",
       "2              bit                6           0.987740   \n",
       "3              one                3           0.969355   \n",
       "4            laugh                1           0.914474   \n",
       "\n",
       "                                      related_senses  \\\n",
       "0  ['English#6', 'ENGLISH#6', 'bengali#1', 'Sinha...   \n",
       "1  ['Saturday#2', 'SATURDAY#2', 'SUNDAY#3', 'sund...   \n",
       "2  ['Bit#5', 'BIT#5', 'stuff#3', 'Stuff#2', 'Real...   \n",
       "3  ['One#3', 'ONE#3', 'List#10', 'Top#8', 'TOP#9'...   \n",
       "4  ['LAUGH#1', 'Laugh#2', 'giggle#1', 'Giggle#1',...   \n",
       "\n",
       "                                             hhm_map  \\\n",
       "0  {'west_germanic': {'rev_map': {'direct': [{'hy...   \n",
       "1  {'weekday': {'rev_map': {'direct': [{'hyponyms...   \n",
       "2  {'be': {'rev_map': {'l1': [{'hyponyms': ['feel...   \n",
       "3  {'digit': {'rev_map': {'direct': [{'hyponyms':...   \n",
       "4  {'laugh': {'rev_map': {'l1': [{'hyponyms': [],...   \n",
       "\n",
       "                                            hypernym  \\\n",
       "0  ['west_germanic', 'nation', 'humanistic_discip...   \n",
       "1                            ['weekday', 'rest_day']   \n",
       "2  ['be', 'fragment', 'look', 'touch', 'unit_of_m...   \n",
       "3  ['digit', 'unit', 'travel', 'line', 'dispute',...   \n",
       "4  ['laugh', 'express_emotion', 'complain', 'utte...   \n",
       "\n",
       "                                             hyponym  \\\n",
       "0  [['middle_english', 'received_pronunciation', ...   \n",
       "1               [['whitmonday', 'whit-tuesday'], []]   \n",
       "2  [['glitter', 'cut', 'sound', 'make', 'pass_off...   \n",
       "3  [['monad', 'singleton'], [], ['stalk', 'tailga...   \n",
       "4  [[], ['cachinnate', 'bellylaugh', 'cackle', 'g...   \n",
       "\n",
       "                                             meronym  \\\n",
       "0                                   [[], [], [], []]   \n",
       "1                                           [[], []]   \n",
       "2  [[], [], [], [], [], [], [], [], [], [], [], [...   \n",
       "3  [[], [], [], [], [], [], [], [], [], ['feather...   \n",
       "4                   [[], [], [], [], [], [], [], []]   \n",
       "\n",
       "                                hypernym_from_corpus  \\\n",
       "0                                                 []   \n",
       "1                                                 []   \n",
       "2  ['be', 'look', 'time', 'performance', 'part', ...   \n",
       "3  ['digit', 'line', 'sport', 'result', 'be', 'ch...   \n",
       "4              ['laugh', 'utter', 'sound', 'moment']   \n",
       "\n",
       "                                 hyponym_from_corpus  \\\n",
       "0                                                 []   \n",
       "1                                                 []   \n",
       "2  [['glitter', 'cut', 'sound', 'make', 'pass_off...   \n",
       "3  [['monad', 'singleton'], ['terrace', 'serratio...   \n",
       "4                                   [[], [], [], []]   \n",
       "\n",
       "                                 meronym_from_corpus  \n",
       "0                                                 []  \n",
       "1                                                 []  \n",
       "2  [[], [], [], [], [], [], [], [], [], [], [], [...  \n",
       "3  [[], [], ['feather'], [], [], [], [], [], [], ...  \n",
       "4                                   [[], [], [], []]  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hhm_mappings_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hypernymy Graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper functions - \n",
    "* extract_hypo_mero_map: Extracts mappings of hypernym-hyponym and meronym for selected word. Set the *only_from_corpus* flag True, to extract and maintain only those words that exist in the corpus.\n",
    "* generate_plot_indices - Generates plot indices for nodes and edges to be used while plotting.\n",
    "* make_annotations - Makes annotations to the plot.\n",
    "* generate_plot - Main function that uses the last 3 helper functions to generate plot for hhm mappings and shows them.\n",
    "\n",
    "**NOTE** - If the plot does not show up in the ouput, restart kernel and clear output, and rerun the cells. This is a known issue of plotly with IPython."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_hypo_mero_map(word, hhm_mappings_df, only_from_corpus=True):\n",
    "    subset_df = hhm_mappings_df[hhm_mappings_df[\"sense_group_name\"]==word]\n",
    "    \n",
    "    rows_to_consider = [\"hypernym\", \"hyponym\", \"meronym\"]\n",
    "    if only_from_corpus:\n",
    "        rows_to_consider = [\"hypernym_from_corpus\", \"hyponym_from_corpus\", \"meronym_from_corpus\"]\n",
    "\n",
    "    hypo_mero_map = {}\n",
    "    for _, row in subset_df[rows_to_consider].iterrows():\n",
    "        hyper_str, hypo_str, mero_str = row\n",
    "        hyper_list = ast.literal_eval(hyper_str)\n",
    "        hypo_list = ast.literal_eval(hypo_str)\n",
    "        mero_list = ast.literal_eval(mero_str)\n",
    "        \n",
    "        for hypernym, hyponyms, meronyms in zip(hyper_list, hypo_list, mero_list):\n",
    "            \n",
    "            if hypernym in hypo_mero_map:\n",
    "                hypo_mero_map[hypernym][\"hyponyms\"] =  list(set(hypo_mero_map[hypernym][\"hyponyms\"] + hyponyms))\n",
    "                hypo_mero_map[hypernym][\"meronyms\"] =  list(set(hypo_mero_map[hypernym][\"meronyms\"] + meronyms))\n",
    "            else:\n",
    "                hypo_mero_map[hypernym] = {}\n",
    "                hypo_mero_map[hypernym][\"hyponyms\"] =  list(set(hyponyms))\n",
    "                hypo_mero_map[hypernym][\"meronyms\"] =  list(set(meronyms))\n",
    "        \n",
    "    return hypo_mero_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_plot_indices(word, hypo_mero_map, top_n=3):   \n",
    "    max_groups = min(top_n, len(hypo_mero_map))\n",
    "    \n",
    "    hyper_start = 0\n",
    "    word_y = 4\n",
    "    word_x = math.ceil(max_groups/2) if max_groups>1 else 0\n",
    "    hyper_y = 6\n",
    "    hyper_x = 0\n",
    "    hypo_x = 0\n",
    "    hypo_y = 2\n",
    "    mero_x = 0\n",
    "    mero_y = 0\n",
    "    label_x = -2\n",
    "    \n",
    "    position = {\n",
    "        \"Hypernyms ->\": [label_x, hyper_y],\n",
    "        \"Word ->\": [label_x, word_y],\n",
    "        \"Hyponyms ->\": [label_x, hypo_y],\n",
    "        \"Meronyms ->\": [label_x, mero_y],\n",
    "        word: [word_x, word_y]\n",
    "    }\n",
    "    edges = []\n",
    "    \n",
    "    keys = list(hypo_mero_map.keys())[:max_groups]\n",
    "    for hyper in keys:\n",
    "        hypo = hypo_mero_map[hyper]['hyponyms']\n",
    "        mero = hypo_mero_map[hyper]['meronyms']\n",
    "        \n",
    "        for i in range(len(hypo)):\n",
    "            if i!=0 and i%3==0:\n",
    "                hypo.insert(i, \"__placeholder__\")\n",
    "\n",
    "        for i in range(len(mero)):\n",
    "            if i!=0 and i%3==0:\n",
    "                mero.insert(i, \"__placeholder__\")\n",
    "        \n",
    "        if hyper==word:\n",
    "            hyper += \"_hypernym\"\n",
    "        \n",
    "        position[hyper] = [hyper_x, hyper_y]\n",
    "        edges.append((word, hyper))\n",
    "        hyper_x +=2\n",
    "\n",
    "        hypo_group = ', '.join(hypo)\n",
    "        position[hypo_group] = [hypo_x, hypo_y]\n",
    "        edges.append((word, hypo_group))\n",
    "        hypo_x +=2\n",
    "        \n",
    "        if len(mero)>0:\n",
    "            mero_group = ', '.join(mero)\n",
    "            position[mero_group] = [mero_x, mero_y]\n",
    "            edges.append((hypo_group, mero_group))\n",
    "            mero_x +=2\n",
    "        \n",
    "    return position, edges\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_annotations(pos, text, font_size=10, font_color='rgb(0,0,0)'):\n",
    "    L=len(pos)\n",
    "    if len(text)!=L:\n",
    "        raise ValueError('The lists pos and text must have the same len')\n",
    "    annotations = []\n",
    "    labels = [l.replace(\", __placeholder__,\",\"<br>\") for l in text]\n",
    "    for n, k in enumerate(list(pos.keys())):\n",
    "        annotations.append(\n",
    "            dict(\n",
    "                text=labels[n], # or replace labels with a different list for the text within the circle\n",
    "                x=pos[k][0], y=pos[k][1],\n",
    "                xref='x1', yref='y1',\n",
    "                font=dict(color=font_color, size=font_size),\n",
    "                showarrow=False)\n",
    "        )\n",
    "    return annotations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_plot(word, hhm_mappings_df, only_in_corpus=False, top_n=3):\n",
    "    hypo_mero_map = extract_hypo_mero_map(word, hhm_mappings_df, only_from_corpus=only_in_corpus)\n",
    "    position, edges = generate_plot_indices(word, hypo_mero_map, top_n)\n",
    "    \n",
    "    labels = list(position.keys())\n",
    "    hover_labels = [l.replace(\", __placeholder__\", \"\") for l in labels]\n",
    "    \n",
    "    Xn = [position[k][0] for k in labels]\n",
    "    Yn = [position[k][1] for k in labels]\n",
    "\n",
    "    Xe = []\n",
    "    Ye = []\n",
    "    for edge in edges:\n",
    "        Xe+=[position[edge[0]][0],position[edge[1]][0], None]\n",
    "        Ye+=[position[edge[0]][1],position[edge[1]][1], None]\n",
    "        \n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(go.Scatter(x=Xe,\n",
    "                       y=Ye,\n",
    "                       mode='lines',\n",
    "                       line=dict(color='rgb(210,210,210)', width=1),\n",
    "                       hoverinfo='none'\n",
    "                       ))\n",
    "    fig.add_trace(go.Scatter(y=Yn,\n",
    "                      x=Xn,\n",
    "                      mode='markers',\n",
    "                      marker=dict(symbol='circle-dot',\n",
    "                                    size=0.0001,\n",
    "                                    color='#6175c1',    #'#DB4551',\n",
    "                                    line=dict(color='rgb(50,50,50)', width=1)\n",
    "                                    ),\n",
    "                      text=hover_labels,\n",
    "                      hoverinfo='text',\n",
    "                      opacity=0.8\n",
    "                      ))\n",
    "    axis = dict(showline=False, # hide axis line, grid, ticklabels and  title\n",
    "            zeroline=False,\n",
    "            showgrid=False,\n",
    "            showticklabels=False,\n",
    "            )\n",
    "\n",
    "    fig.update_layout(title= f'Hypernym-Hyponym-Meronym Tree - {word}',\n",
    "                  annotations=make_annotations(position, labels),\n",
    "                  font_size=12,\n",
    "                  showlegend=False,\n",
    "                  xaxis=axis,\n",
    "                  yaxis=axis,\n",
    "                  margin=dict(l=40, r=40, b=85, t=100),\n",
    "                  hovermode='closest',\n",
    "                  plot_bgcolor='rgb(248,248,248)'\n",
    "                  )\n",
    "    fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change the word to one of your choice and re-run to generate graph for that word.\n",
    "Arguments - \n",
    "* *word* - The word for which HHM mappings are to be extracted.\n",
    "* *hhm_mappings_df* - HHM mappings dataframe created in the previous step.\n",
    "* *only_in_corpus* - Flag to be set if the output graph should only show the words that are there in the corpus. This will limit the hypernym, hyponyms and meronyms shown for the focus word.\n",
    "* *top_n* - Top *N* groups to be plotted. Default 3. If the number of HHM groups are less than top_n, then all those groups will be shown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hoverinfo": "none",
         "line": {
          "color": "rgb(210,210,210)",
          "width": 1
         },
         "mode": "lines",
         "type": "scatter",
         "x": [
          2,
          0,
          null,
          2,
          0,
          null,
          0,
          0,
          null,
          2,
          2,
          null,
          2,
          2,
          null,
          2,
          2,
          null,
          2,
          4,
          null,
          2,
          4,
          null
         ],
         "y": [
          4,
          6,
          null,
          4,
          2,
          null,
          2,
          0,
          null,
          4,
          6,
          null,
          4,
          2,
          null,
          2,
          0,
          null,
          4,
          6,
          null,
          4,
          2,
          null
         ]
        },
        {
         "hoverinfo": "text",
         "marker": {
          "color": "#6175c1",
          "line": {
           "color": "rgb(50,50,50)",
           "width": 1
          },
          "size": 0.0001,
          "symbol": "circle-dot"
         },
         "mode": "markers",
         "opacity": 0.8,
         "text": [
          "Hypernyms ->",
          "Word ->",
          "Hyponyms ->",
          "Meronyms ->",
          "day",
          "time_period",
          "midafternoon, weeknight, evening, lunar_day, afternoon, wedding_night",
          "midnight, morning, saturday, evening, late-night_hour, small_hours, sunday, lights-out",
          "time_unit",
          "man_hour, yesterday, morrow, date, sidereal_hour, tomorrow, eve, today",
          "quarter-hour, night, quarter, hour, minute, noon, half-hour, day",
          "work_time",
          "shift, workday"
         ],
         "type": "scatter",
         "x": [
          -2,
          -2,
          -2,
          -2,
          2,
          0,
          0,
          0,
          2,
          2,
          2,
          4,
          4
         ],
         "y": [
          6,
          4,
          2,
          0,
          4,
          6,
          2,
          0,
          6,
          2,
          0,
          6,
          2
         ]
        }
       ],
       "layout": {
        "annotations": [
         {
          "font": {
           "color": "rgb(0,0,0)",
           "size": 10
          },
          "showarrow": false,
          "text": "Hypernyms ->",
          "x": -2,
          "xref": "x",
          "y": 6,
          "yref": "y"
         },
         {
          "font": {
           "color": "rgb(0,0,0)",
           "size": 10
          },
          "showarrow": false,
          "text": "Word ->",
          "x": -2,
          "xref": "x",
          "y": 4,
          "yref": "y"
         },
         {
          "font": {
           "color": "rgb(0,0,0)",
           "size": 10
          },
          "showarrow": false,
          "text": "Hyponyms ->",
          "x": -2,
          "xref": "x",
          "y": 2,
          "yref": "y"
         },
         {
          "font": {
           "color": "rgb(0,0,0)",
           "size": 10
          },
          "showarrow": false,
          "text": "Meronyms ->",
          "x": -2,
          "xref": "x",
          "y": 0,
          "yref": "y"
         },
         {
          "font": {
           "color": "rgb(0,0,0)",
           "size": 10
          },
          "showarrow": false,
          "text": "day",
          "x": 2,
          "xref": "x",
          "y": 4,
          "yref": "y"
         },
         {
          "font": {
           "color": "rgb(0,0,0)",
           "size": 10
          },
          "showarrow": false,
          "text": "time_period",
          "x": 0,
          "xref": "x",
          "y": 6,
          "yref": "y"
         },
         {
          "font": {
           "color": "rgb(0,0,0)",
           "size": 10
          },
          "showarrow": false,
          "text": "midafternoon, weeknight, evening<br> lunar_day, afternoon, wedding_night",
          "x": 0,
          "xref": "x",
          "y": 2,
          "yref": "y"
         },
         {
          "font": {
           "color": "rgb(0,0,0)",
           "size": 10
          },
          "showarrow": false,
          "text": "midnight, morning, saturday<br> evening, late-night_hour<br> small_hours, sunday, lights-out",
          "x": 0,
          "xref": "x",
          "y": 0,
          "yref": "y"
         },
         {
          "font": {
           "color": "rgb(0,0,0)",
           "size": 10
          },
          "showarrow": false,
          "text": "time_unit",
          "x": 2,
          "xref": "x",
          "y": 6,
          "yref": "y"
         },
         {
          "font": {
           "color": "rgb(0,0,0)",
           "size": 10
          },
          "showarrow": false,
          "text": "man_hour, yesterday, morrow<br> date, sidereal_hour<br> tomorrow, eve, today",
          "x": 2,
          "xref": "x",
          "y": 2,
          "yref": "y"
         },
         {
          "font": {
           "color": "rgb(0,0,0)",
           "size": 10
          },
          "showarrow": false,
          "text": "quarter-hour, night, quarter<br> hour, minute<br> noon, half-hour, day",
          "x": 2,
          "xref": "x",
          "y": 0,
          "yref": "y"
         },
         {
          "font": {
           "color": "rgb(0,0,0)",
           "size": 10
          },
          "showarrow": false,
          "text": "work_time",
          "x": 4,
          "xref": "x",
          "y": 6,
          "yref": "y"
         },
         {
          "font": {
           "color": "rgb(0,0,0)",
           "size": 10
          },
          "showarrow": false,
          "text": "shift, workday",
          "x": 4,
          "xref": "x",
          "y": 2,
          "yref": "y"
         }
        ],
        "font": {
         "size": 12
        },
        "hovermode": "closest",
        "margin": {
         "b": 85,
         "l": 40,
         "r": 40,
         "t": 100
        },
        "plot_bgcolor": "rgb(248,248,248)",
        "showlegend": false,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Hypernym-Hyponym-Meronym Tree - day"
        },
        "xaxis": {
         "showgrid": false,
         "showline": false,
         "showticklabels": false,
         "zeroline": false
        },
        "yaxis": {
         "showgrid": false,
         "showline": false,
         "showticklabels": false,
         "zeroline": false
        }
       }
      },
      "text/html": [
       "<div>\n",
       "        \n",
       "        \n",
       "            <div id=\"51dc2810-f43b-4b49-90d6-8ada056fc54a\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n",
       "            <script type=\"text/javascript\">\n",
       "                require([\"plotly\"], function(Plotly) {\n",
       "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
       "                    \n",
       "                if (document.getElementById(\"51dc2810-f43b-4b49-90d6-8ada056fc54a\")) {\n",
       "                    Plotly.newPlot(\n",
       "                        '51dc2810-f43b-4b49-90d6-8ada056fc54a',\n",
       "                        [{\"hoverinfo\": \"none\", \"line\": {\"color\": \"rgb(210,210,210)\", \"width\": 1}, \"mode\": \"lines\", \"type\": \"scatter\", \"x\": [2, 0, null, 2, 0, null, 0, 0, null, 2, 2, null, 2, 2, null, 2, 2, null, 2, 4, null, 2, 4, null], \"y\": [4, 6, null, 4, 2, null, 2, 0, null, 4, 6, null, 4, 2, null, 2, 0, null, 4, 6, null, 4, 2, null]}, {\"hoverinfo\": \"text\", \"marker\": {\"color\": \"#6175c1\", \"line\": {\"color\": \"rgb(50,50,50)\", \"width\": 1}, \"size\": 0.0001, \"symbol\": \"circle-dot\"}, \"mode\": \"markers\", \"opacity\": 0.8, \"text\": [\"Hypernyms ->\", \"Word ->\", \"Hyponyms ->\", \"Meronyms ->\", \"day\", \"time_period\", \"midafternoon, weeknight, evening, lunar_day, afternoon, wedding_night\", \"midnight, morning, saturday, evening, late-night_hour, small_hours, sunday, lights-out\", \"time_unit\", \"man_hour, yesterday, morrow, date, sidereal_hour, tomorrow, eve, today\", \"quarter-hour, night, quarter, hour, minute, noon, half-hour, day\", \"work_time\", \"shift, workday\"], \"type\": \"scatter\", \"x\": [-2, -2, -2, -2, 2, 0, 0, 0, 2, 2, 2, 4, 4], \"y\": [6, 4, 2, 0, 4, 6, 2, 0, 6, 2, 0, 6, 2]}],\n",
       "                        {\"annotations\": [{\"font\": {\"color\": \"rgb(0,0,0)\", \"size\": 10}, \"showarrow\": false, \"text\": \"Hypernyms ->\", \"x\": -2, \"xref\": \"x\", \"y\": 6, \"yref\": \"y\"}, {\"font\": {\"color\": \"rgb(0,0,0)\", \"size\": 10}, \"showarrow\": false, \"text\": \"Word ->\", \"x\": -2, \"xref\": \"x\", \"y\": 4, \"yref\": \"y\"}, {\"font\": {\"color\": \"rgb(0,0,0)\", \"size\": 10}, \"showarrow\": false, \"text\": \"Hyponyms ->\", \"x\": -2, \"xref\": \"x\", \"y\": 2, \"yref\": \"y\"}, {\"font\": {\"color\": \"rgb(0,0,0)\", \"size\": 10}, \"showarrow\": false, \"text\": \"Meronyms ->\", \"x\": -2, \"xref\": \"x\", \"y\": 0, \"yref\": \"y\"}, {\"font\": {\"color\": \"rgb(0,0,0)\", \"size\": 10}, \"showarrow\": false, \"text\": \"day\", \"x\": 2, \"xref\": \"x\", \"y\": 4, \"yref\": \"y\"}, {\"font\": {\"color\": \"rgb(0,0,0)\", \"size\": 10}, \"showarrow\": false, \"text\": \"time_period\", \"x\": 0, \"xref\": \"x\", \"y\": 6, \"yref\": \"y\"}, {\"font\": {\"color\": \"rgb(0,0,0)\", \"size\": 10}, \"showarrow\": false, \"text\": \"midafternoon, weeknight, evening<br> lunar_day, afternoon, wedding_night\", \"x\": 0, \"xref\": \"x\", \"y\": 2, \"yref\": \"y\"}, {\"font\": {\"color\": \"rgb(0,0,0)\", \"size\": 10}, \"showarrow\": false, \"text\": \"midnight, morning, saturday<br> evening, late-night_hour<br> small_hours, sunday, lights-out\", \"x\": 0, \"xref\": \"x\", \"y\": 0, \"yref\": \"y\"}, {\"font\": {\"color\": \"rgb(0,0,0)\", \"size\": 10}, \"showarrow\": false, \"text\": \"time_unit\", \"x\": 2, \"xref\": \"x\", \"y\": 6, \"yref\": \"y\"}, {\"font\": {\"color\": \"rgb(0,0,0)\", \"size\": 10}, \"showarrow\": false, \"text\": \"man_hour, yesterday, morrow<br> date, sidereal_hour<br> tomorrow, eve, today\", \"x\": 2, \"xref\": \"x\", \"y\": 2, \"yref\": \"y\"}, {\"font\": {\"color\": \"rgb(0,0,0)\", \"size\": 10}, \"showarrow\": false, \"text\": \"quarter-hour, night, quarter<br> hour, minute<br> noon, half-hour, day\", \"x\": 2, \"xref\": \"x\", \"y\": 0, \"yref\": \"y\"}, {\"font\": {\"color\": \"rgb(0,0,0)\", \"size\": 10}, \"showarrow\": false, \"text\": \"work_time\", \"x\": 4, \"xref\": \"x\", \"y\": 6, \"yref\": \"y\"}, {\"font\": {\"color\": \"rgb(0,0,0)\", \"size\": 10}, \"showarrow\": false, \"text\": \"shift, workday\", \"x\": 4, \"xref\": \"x\", \"y\": 2, \"yref\": \"y\"}], \"font\": {\"size\": 12}, \"hovermode\": \"closest\", \"margin\": {\"b\": 85, \"l\": 40, \"r\": 40, \"t\": 100}, \"plot_bgcolor\": \"rgb(248,248,248)\", \"showlegend\": false, \"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"title\": {\"text\": \"Hypernym-Hyponym-Meronym Tree - day\"}, \"xaxis\": {\"showgrid\": false, \"showline\": false, \"showticklabels\": false, \"zeroline\": false}, \"yaxis\": {\"showgrid\": false, \"showline\": false, \"showticklabels\": false, \"zeroline\": false}},\n",
       "                        {\"responsive\": true}\n",
       "                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('51dc2810-f43b-4b49-90d6-8ada056fc54a');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })\n",
       "                };\n",
       "                });\n",
       "            </script>\n",
       "        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "word = \"day\"\n",
    "generate_plot(word, hhm_mappings_df, only_in_corpus=False, top_n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
