{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from gensim.models import KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"sensegram_package/\")\n",
    "import sensegram\n",
    "from wsd import WSD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_directory = os.path.join(os.getcwd(), \"data\")\n",
    "corpus_fpath = os.path.join(data_directory, \"corpus.txt\")\n",
    "sense_vectors_fpath = os.path.join(data_directory, \"model\", \"wiki.txt.clusters.minsize5-1000-sum-score-20.sense_vectors\")\n",
    "word_vectors_fpath = os.path.join(data_directory, \"model\", \"wiki.txt.word_vectors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sense_vectors' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-72b3a9aa298e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0msence_vectors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msensegram\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSenseGram\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_word2vec_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msense_vectors_fpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbinary\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mword_vectors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKeyedVectors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_word2vec_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword_vectors_fpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbinary\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0municode_errors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mwsd_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWSD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msense_vectors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword_vectors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwindow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sim'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilter_ctx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Could not find vector files. Check file paths and ensure the right files exists\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sense_vectors' is not defined"
     ]
    }
   ],
   "source": [
    "if os.path.exists(sense_vectors_fpath) and os.path.exists(word_vectors_fpath):\n",
    "    sense_vectors = sensegram.SenseGram.load_word2vec_format(sense_vectors_fpath, binary=False)\n",
    "    word_vectors = KeyedVectors.load_word2vec_format(word_vectors_fpath, binary=False, unicode_errors=\"ignore\")\n",
    "    wsd_model = WSD(sense_vectors, word_vectors, window=5, method='sim', filter_ctx=3)\n",
    "else:\n",
    "    print(\"Could not find vector files. Check file paths and ensure the right files exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "wsd_model = WSD(sence_vectors, word_vectors, window=15, method='sim', verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(corpus_fpath, \"r\") as f:\n",
    "    corpus_data = f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get all senses of a word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities of the senses:\n",
      "[('Table#1', 1.0), ('Table#2', 1.0), ('Table#3', 1.0), ('Table#4', 1.0), ('table#1', 1.0), ('table#2', 1.0), ('table#3', 1.0), ('table#4', 1.0)]\n",
      "\n",
      "\n",
      "Table#1\n",
      "====================\n",
      "table#1 0.996316\n",
      "TABLE#1 0.993647\n",
      "PAGE#2 0.989991\n",
      "page#2 0.989991\n",
      "WINDOW#2 0.989900\n",
      "Window#3 0.989900\n",
      "window#2 0.989900\n",
      "Scale#2 0.989745\n",
      "scale#2 0.989745\n",
      "SCALE#2 0.989745\n",
      "\n",
      "\n",
      "Table#2\n",
      "====================\n",
      "TABLE#2 1.000000\n",
      "Row#3 0.869726\n",
      "row#3 0.869726\n",
      "ROW#3 0.856643\n",
      "Stack#3 0.829349\n",
      "Box#3 0.826571\n",
      "BOX#2 0.826571\n",
      "stack#3 0.825068\n",
      "STACK#3 0.824239\n",
      "BOWL#3 0.813412\n",
      "\n",
      "\n",
      "Table#3\n",
      "====================\n",
      "TABLE#3 0.939938\n",
      "table#3 0.934190\n",
      "Boundary_Markers#5 0.845184\n",
      "Catchment_Basins#2 0.826906\n",
      "contents#2 0.825448\n",
      "CONTENTS#2 0.825448\n",
      "Contents#2 0.824324\n",
      "tables#1 0.806271\n",
      "NUMBERS#3 0.804637\n",
      "Tables#1 0.796628\n",
      "\n",
      "\n",
      "Table#4\n",
      "====================\n",
      "TABLE#4 0.919513\n",
      "KOI_Rp#4 0.912018\n",
      "hlt_fst#2 0.909054\n",
      "GB_NRT#2 0.905041\n",
      "Algonquin_Round#1 0.905017\n",
      "AYP_Data#2 0.904868\n",
      "Sentry_Risk#1 0.900897\n",
      "Peutinger#2 0.900774\n",
      "Simplified_Characters#2 0.897952\n",
      "Global_Descriptor#1 0.897648\n",
      "\n",
      "\n",
      "table#1\n",
      "====================\n",
      "Table#1 0.996316\n",
      "TABLE#1 0.994172\n",
      "page#2 0.990908\n",
      "PAGE#2 0.990908\n",
      "standard#2 0.990807\n",
      "Standard#2 0.990807\n",
      "STANDARD#2 0.990807\n",
      "SCALE#2 0.990401\n",
      "Scale#2 0.990401\n",
      "scale#2 0.990401\n",
      "\n",
      "\n",
      "table#2\n",
      "====================\n",
      "sortable_table#1 0.807735\n",
      "Table#2 0.789767\n",
      "TABLE#2 0.789767\n",
      "leftmost_column#1 0.736741\n",
      "Tables#3 0.735492\n",
      "tableau#2 0.727480\n",
      "Row#3 0.727201\n",
      "row#3 0.727201\n",
      "map#5 0.724968\n",
      "column_headings#1 0.721140\n",
      "\n",
      "\n",
      "table#3\n",
      "====================\n",
      "TABLE#3 0.996218\n",
      "Table#3 0.934190\n",
      "NUMBERS#3 0.867299\n",
      "Boundary_Markers#5 0.865554\n",
      "NUMBER#6 0.857856\n",
      "figure#2 0.843562\n",
      "Figure#2 0.843562\n",
      "Markers#1 0.824250\n",
      "Coordinates#2 0.823193\n",
      "digits#2 0.819004\n",
      "\n",
      "\n",
      "table#4\n",
      "====================\n",
      "Peutinger#2 0.931094\n",
      "Sivtsev#2 0.928467\n",
      "TABLE#4 0.922475\n",
      "ITSF#1 0.918510\n",
      "hlt_fst#2 0.912997\n",
      "File_Allocation#2 0.907930\n",
      "Global_Descriptor#1 0.901716\n",
      "d_h√¥te#2 0.898206\n",
      "AYP_Data#2 0.898110\n",
      "Sentry_Risk#1 0.892614\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_word = \"table\"\n",
    "\n",
    "print(\"Probabilities of the senses:\\n{}\\n\\n\".format(sence_vectors.get_senses(test_word, ignore_case=True)))\n",
    "\n",
    "for sense_id, prob in sence_vectors.get_senses(test_word, ignore_case=True):\n",
    "    print(sense_id)\n",
    "    print(\"=\"*20)\n",
    "    for rsense_id, sim in sence_vectors.wv.most_similar(sense_id):\n",
    "        print(\"{} {:f}\".format(rsense_id, sim))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get disambiguated sense of the word, using corpus as context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "wsd_model = WSD(sence_vectors, word_vectors, window=15, method='prob', verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted context words:\n",
      "['leftover', 'today', 'pizza', 'two', 'listening', 'english', 'saturday', 'just', 'ot', 'good', 'hangover', 'really', 'little', 'making', 'stop', 'slices']\n",
      "Senses of a target word:\n",
      "[('table#1', 1.0), ('table#2', 1.0), ('table#3', 1.0), ('table#4', 1.0)]\n",
      "Significance scores of context words:\n",
      "[0.37694023295858664, 0.5826593097827415, 0.7275173661671048, 0.3462219279577813, 0.32113965964726915, 0.6235405044059925, 0.314476217064492, 0.6094166324483048, 0.19088531161143885, 0.47508827794669944, 0.3897201415017436, 0.6215423778084821, 0.6857576958729588, 0.575916585269904, 0.7006624524726446, 0.7680371969757536]\n",
      "Context words:\n",
      "slices\t0.768\n",
      "pizza\t0.728\n",
      "stop\t0.701\n",
      "('table#2', [0.2706353009709064, 0.9591583572384959, 0.40617065436041355, 0.6940131864117054])\n"
     ]
    }
   ],
   "source": [
    "print(wsd_model.disambiguate(corpus_data, test_word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'WSD' object has no attribute 'dis_text'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-d4dba6c9f5d7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mwsd_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdis_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_word\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'WSD' object has no attribute 'dis_text'"
     ]
    }
   ],
   "source": [
    "wsd_model.dis_text(corpus, test_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
