{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Sense Vectors to identify Word sense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Library Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "from gensim.models import KeyedVectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Append the github repo to system path, and import modules from it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"sensegram_package/\")\n",
    "import sensegram\n",
    "from wsd import WSD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_directory = os.path.join(os.getcwd(), \"data\")\n",
    "corpus_fpath = os.path.join(data_directory, \"corpus.txt\")\n",
    "sense_vectors_fpath = os.path.join(data_directory, \"model\", \"wiki.txt.clusters.minsize5-1000-sum-score-20.sense_vectors\")\n",
    "word_vectors_fpath = os.path.join(data_directory, \"model\", \"wiki.txt.word_vectors\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the sense and word vector files. This may take some time, owing to the large file size of the vector files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sense_vectors' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-72b3a9aa298e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0msence_vectors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msensegram\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSenseGram\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_word2vec_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msense_vectors_fpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbinary\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mword_vectors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKeyedVectors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_word2vec_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword_vectors_fpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbinary\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0municode_errors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mwsd_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWSD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msense_vectors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword_vectors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwindow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sim'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilter_ctx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Could not find vector files. Check file paths and ensure the right files exists\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sense_vectors' is not defined"
     ]
    }
   ],
   "source": [
    "s = time.time()\n",
    "if os.path.exists(sense_vectors_fpath) and os.path.exists(word_vectors_fpath):\n",
    "    sense_vectors = sensegram.SenseGram.load_word2vec_format(sense_vectors_fpath, binary=False)\n",
    "    word_vectors = KeyedVectors.load_word2vec_format(word_vectors_fpath, binary=False, unicode_errors=\"ignore\")\n",
    "    print(f\"Took {time.time()-s}seconds to load vector files\")\n",
    "else:\n",
    "    print(\"Could not find vector files. Check file paths and ensure the right files exists\")\n",
    "del s\n",
    "\n",
    "print(\"Reading the corpus now!\")\n",
    "with open(corpus_fpath, \"r\") as f:\n",
    "    corpus_data = f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get all senses of a word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the sense vectors, load all possible senses for the given word.  \n",
    "The output prints the sense *Word#&lt;sense-number&gt;* followed by the probabilities of that word matching other words with similar sense. This table can help us provide logical names of different sense groups. For example, running the code for the word \"**table**\" gives the following output -  \n",
    "```\n",
    "Probabilities of the senses:\n",
    "[('Table#1', 1.0), ('Table#2', 1.0), ('Table#3', 1.0), ('Table#4', 1.0), ('table#1', 1.0), ('table#2', 1.0), ('table#3', 1.0), ('table#4', 1.0)]\n",
    "\n",
    "\n",
    "Table#1\n",
    "====================\n",
    "table#1 0.996316\n",
    "TABLE#1 0.993647\n",
    "PAGE#2 0.989991\n",
    "page#2 0.989991\n",
    "WINDOW#2 0.989900\n",
    "Window#3 0.989900\n",
    "window#2 0.989900\n",
    "Scale#2 0.989745\n",
    "scale#2 0.989745\n",
    "SCALE#2 0.989745\n",
    "\n",
    "\n",
    "Table#2\n",
    "====================\n",
    "TABLE#2 1.000000\n",
    "Row#3 0.869726\n",
    "row#3 0.869726\n",
    "ROW#3 0.856643\n",
    "Stack#3 0.829349\n",
    "Box#3 0.826571\n",
    "BOX#2 0.826571\n",
    "stack#3 0.825068\n",
    "STACK#3 0.824239\n",
    "BOWL#3 0.813412\n",
    "\n",
    "\n",
    "Table#3\n",
    "====================\n",
    "TABLE#3 0.939938\n",
    "table#3 0.934190\n",
    "Boundary_Markers#5 0.845184\n",
    "Catchment_Basins#2 0.826906\n",
    "contents#2 0.825448\n",
    "CONTENTS#2 0.825448\n",
    "Contents#2 0.824324\n",
    "tables#1 0.806271\n",
    "NUMBERS#3 0.804637\n",
    "Tables#1 0.796628\n",
    "....\n",
    "\n",
    "```\n",
    "Few things we can see from the output - \n",
    "* Since we have set *ignore_case=True*, the output shows 4 senses for *Table*, and 4 for *table*.\n",
    "* Looking at the related words for each sense, we can attribute the following logical groups to few of the senses - \n",
    "    - Table#2 - Data table.  \n",
    "    - Table#3 - Table of contents.\n",
    "    - table#4 - Hotel/Furniture.\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sence_vectors' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-bc33cf3ebcbd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtest_word\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"table\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Probabilities of the senses:\\n{}\\n\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msence_vectors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_senses\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_word\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_case\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msense_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprob\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msence_vectors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_senses\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_word\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_case\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sence_vectors' is not defined"
     ]
    }
   ],
   "source": [
    "test_word = \"table\"\n",
    "\n",
    "print(\"Probabilities of the senses:\\n{}\\n\\n\".format(sense_vectors.get_senses(test_word, ignore_case=True)))\n",
    "\n",
    "for sense_id, prob in sense_vectors.get_senses(test_word, ignore_case=True):\n",
    "    print(sense_id)\n",
    "    print(\"=\"*20)\n",
    "    for rsense_id, sim in sense_vectors.wv.most_similar(sense_id):\n",
    "        print(\"{} {:f}\".format(rsense_id, sim))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get disambiguated sense of the word, using corpus as context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Input\n",
    "To understand the word's sense in a given context, we use the *WSD* class from the sensegram library.  \n",
    "The WSD model takes the following key parameters to decide word sense based on corpus context - \n",
    "* vectors - Both sense and word vector models loaded earlier.  \n",
    "  \n",
    "  \n",
    "* method - To calculate the sense of the word, the library averages the sense scores of all the surrounding context words and compares it with different senses of the target word. For this comparison, there are two available metrics - \n",
    " - sim: Uses cosine distance\n",
    " - prob: Use log probability score  \n",
    "  \n",
    "  \n",
    "* window - This is the window(Â±) that the model looks into, to decide the word context.   \n",
    "For example, if our target word is *table*,   \n",
    "with the context of *\"we load the our data into a data-frame table object and count the number of rows/columns using the .shape method\"*  \n",
    " 1. a window of 3 would consider the following 6(3 on the left, and 3 on the right) words around our context word to find the sense of the word - *into, a, data-frame, object, and, count*  \n",
    " 2. a window of 5 would use the following context - *our, data, into, a, data-frame, table, object, and, count, the, number*  \n",
    "  \n",
    "  \n",
    "* verbose - Allows to print intermediate outputs while running the disambiguation code\n",
    "\n",
    "<hr>  \n",
    "     \n",
    "Some food-for-thought regarding the usage of WSD module - \n",
    " - Do note that while stopwords like *and* and *the* are considered in the context of the the target word, they are dropped while disambiguating the sense of our target.\n",
    " - While it may seem ideal to choose a high value of window for getting the sense of the target word, it may happen that the wider window results in an less accurate output, as it averages across all possible senses.\n",
    " - The library considers, and disambiguates, only the first occurance of the target word in the context. For a large corpus, it would be ideal to first split the corpus and generate contexts using an external helper function, and then iteratively get the sense for the target word across all occurances in the corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "wsd_model = WSD(sense_vectors, word_vectors, window=15, method='prob', verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted context words:\n",
      "['leftover', 'today', 'pizza', 'two', 'listening', 'english', 'saturday', 'just', 'ot', 'good', 'hangover', 'really', 'little', 'making', 'stop', 'slices']\n",
      "Senses of a target word:\n",
      "[('table#1', 1.0), ('table#2', 1.0), ('table#3', 1.0), ('table#4', 1.0)]\n",
      "Significance scores of context words:\n",
      "[0.37694023295858664, 0.5826593097827415, 0.7275173661671048, 0.3462219279577813, 0.32113965964726915, 0.6235405044059925, 0.314476217064492, 0.6094166324483048, 0.19088531161143885, 0.47508827794669944, 0.3897201415017436, 0.6215423778084821, 0.6857576958729588, 0.575916585269904, 0.7006624524726446, 0.7680371969757536]\n",
      "Context words:\n",
      "slices\t0.768\n",
      "pizza\t0.728\n",
      "stop\t0.701\n",
      "('table#2', [0.2706353009709064, 0.9591583572384959, 0.40617065436041355, 0.6940131864117054])\n"
     ]
    }
   ],
   "source": [
    "print(wsd_model.disambiguate(corpus_data, test_word))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5> Output </h5>  \n",
    "\n",
    "Running the Sense disambiguation code generates following lines of output -  \n",
    "1. Prints the context words extracted from the corpus.\n",
    "- Prints possible senses of the word, with their respective probabilities(without considering the context)\n",
    "- Prints the significance score of each context word.\n",
    "- Prints the most significant context words.\n",
    "- **Returns** a tuple of the sense of the word as derived from the context, and match scores(log-probability or cosine-similarity depending on the *method* chosen) of various senses of the target word.  \n",
    "For instance, the output *('table#2', [0.2706353009709064, 0.9591583572384959, 0.40617065436041355, 0.6940131864117054])* indicates the following things regarding our target word -  \n",
    "    - The closest sense of our target word is with *table#2*, with a match score of 0.959(second in the list)\n",
    "    - For the other senses, the match score can be read as follows - \n",
    "    - table#1 - 0.2706\n",
    "    - table#2 - 0.959\n",
    "    - table#3 - 0.406\n",
    "    - table#4 - 0.694\n",
    "\n",
    "Since we had not defined the *ignore_case* argument while initializing the WSD model, it resorts to the default of True, and the output return scores for the 4 senses of the word *table*.  \n",
    "If we chose to ignore case, the output would have match for 8 senses(4-Table; 4-table)\n",
    "<hr> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
